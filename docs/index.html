<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Project</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
<script src="jquery-3.5.0.min.js"></script>



</head>


<body>

<h1 align="middle">Project Milestone - Fluid Dynamic Music Visualizer</h1>
<h2 align="middle">Haoran Guo, Steven Cen, Philip Green</h2>

<br><br>

<div>

<p>Our project aims to combine music data with a fluid simulation, and our main focus so far has been to create the simulation and necessary structure to allow it some ability to present music signals or other data. Using a tutorial (https://gamedevelopment.tutsplus.com/tutorials/how-to-write-a-smoke-shader--cms-25587), we have familiarized ourselves with the main tools we need to be able to implement all graphical/simulation features of our project. </p>


<h3>The Results</h3>
<div align="center" id="scene">  <object type="text/html" data="../smoke.html" width="640px" height="360px"></object>
</div>


<p>As seen above, we are able to render to the webpage using Three.js and have a
  simulation that operates through a few frame buffers and fragment shaders.
  A few aspects that we need are in place: A diffusion shader (and corresponding
  buffer), an advection shader (and a corresponding buffer) that simulates the
  effects of a constant velocity field, and the code for continiously rendering to the
  screen and updating the animation frame. Every 500ms, matching an imaginary "beat",
  parameters for a smoke source are generated; the diffusion shader takes in these uniform inputs
  for random positions to generate smoke sources, with are circular, and then moves
  the smoke density into surrounding pixels. This is rendered onto a frame buffer
  which then passes through the advection shader, which uses a constant vector field of (.5 * (1-x), .5 * (1-y)),
  backwards tracing, and built-in linear interpolation to "move" density around.
  As seen in our results so far, we have not implemented
  more sophisticated concepts such as vorticity and advection of the velocity field itself,
  which will be based on real physics equations to make the material actually look fluid.
   However, our progress has given us a good idea of how we can
  manipulate our simulation, as well as provided us with an actual visualization
  of our work; for example, we are now thinking of trying to generate smoke sources
  according to the pulse of music's pulse, and have the y-coordinate and/or smoke color
  correspond to the frequency of the music in some way. </p>

<h3>Looking Ahead</h3>
<p>Our schedule with modifications can be found below. Right now we have done
  two of the three parts of week 2. Considering where we are right now, we see that the most important part is probably to make our simulation robust by implementing some physics and making sure it is a good looking simulation. This will take priority over any signal processing/music data work, as that can be replaced by simpler, preprocessed data from relevant resources. By focusing on the simulation and visulization we should be able to create a good looking simulation and resulting music visulization, which looks to be our baseline right now. If we have extra time, we can look into music processing and add extra features.
</p>



<h3>Schedule</h3>
<h4>Week 1:</h4>
<p>- Read resources to learn more about fluid dynamics simulations and WebGL/other libraries and software we will need <br>
- Begin a structured codebase for the simulation calculations and website we will present it on
</p>
<h4>Week 2:</h4>
<p>- Create a basic simulation and visualize it <br>
- Look at parameters and add ways to give the visualization variance that we can leverage into our musical visualization <br>
- Make our simulator robust to satisfy the artistic needs
</p>
<h4>Week 3:</h4>
<p> <strike> - Design and implement our extraction of signals and data from music </strike><br>
- Implement physics and add changing velocity field <br>
- Map music data to the relevant parameters for the simulation <br>
<strike>- Attempt to do a full simulation of a music file</strike> <br>
- Attempt to do a simulation of some preprocessed music data
</p>
<h4>Week 4:</h4>
<p>- Extra time for debugging <br>
- Finalize website and rest of deliverable requirements
</p>

<h3>Presentation Link</h3>
<a href="https://docs.google.com/presentation/d/1IlW76ooitt4EdzzoWpSeLH2ye_N4w7lraisGdu7XQzs/edit?usp=sharing">https://docs.google.com/presentation/d/1IlW76ooitt4EdzzoWpSeLH2ye_N4w7lraisGdu7XQzs/edit?usp=sharing<a>


</body>
</html>
